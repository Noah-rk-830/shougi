| 入力名             | 内容説明                                                                 |
|------------------|--------------------------------------------------------------------------|
| **局面情報**       | 現在の将棋の盤面状態（SFEN形式など）例: `lnsgkgsnl/1r5b1/p1ppppppp/...`   |
| **手番**          | 先手 or 後手（`b` or `w`）                                               |
| **持ち駒情報**     | 両者の持ち駒（SFEN形式または内部形式）                                   |
| **着手履歴（任意）** | これまでの手順（方策学習などでは使うが、通常推論には不要）                   |
| **探索パラメータ（任意）** | 探索の深さ、探索ノード数、温度パラメータ（ポリシーの乱数制御）など              |

| 出力名             | 内容説明                                                                 |
|------------------|--------------------------------------------------------------------------|
| **次の最善手**       | 次に指すべき手（例: `7g7f` などのUSI形式）                                     |
| **候補手のリスト**   | 複数の候補手とその評価値（確率・スコアなど）                                     |
| **評価値（Value）** | 現局面の評価値（+数値なら先手有利、-数値なら後手有利）                            |
| **ポリシー（Policy）**| 各合法手に対する確率分布（ソフトマックス後の値、学習済モデルが出力）               |
| **探索木情報（オプション）** | MCTSを使っている場合は、探索ノード数や勝率などの統計情報                        |